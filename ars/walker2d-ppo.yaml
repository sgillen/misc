walker2d-v1-ppo:
    env: Walker2d-v3
    run: PPO
    config:
        kl_coeff: 1.0
        num_sgd_iter: 20
        lr: .0001
        sgd_minibatch_size: 10240
        train_batch_size: 81920
        num_workers: 15
        num_gpus: 1
        batch_mode: complete_episodes
        observation_filter: MeanStdFilter

