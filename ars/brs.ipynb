{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "from seagul.nn import LinearNet\n",
    "import torch\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function we'll try to optimize \n",
    "env = gym.make('InvertedPendulum-v2')\n",
    "def pend_rollout(policy):\n",
    "    max_ep_length = 100\n",
    "    reward_hist = torch.zeros((max_ep_length,1))\n",
    "    action_hist = torch.zeros((max_ep_length,1))\n",
    "    state_hist = torch.zeros((max_ep_length,4))\n",
    "    obs = env.reset()\n",
    "    for i in range(max_ep_length):\n",
    "        action = policy(torch.as_tensor(obs))\n",
    "        obs, reward, done, _ = env.step(action.detach())\n",
    "        action_hist[i,:] = action.clone()\n",
    "        state_hist[i,:] = torch.tensor(obs).clone()\n",
    "        reward_hist[i,:] = reward\n",
    "        #env.render()\n",
    "        if done:\n",
    "            break\n",
    "            \n",
    "    return reward_hist, action_hist, state_hist\n",
    "    \n",
    "    \n",
    "def quad(x):\n",
    "    return -np.power((x-10),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://arxiv.org/pdf/1803.07055.pdf\n",
    "\n",
    "# Basic Random Search\n",
    "def brs(func, step_size = 1, n_delta = 10, exp_noise = .03, num_trials = 1000):\n",
    "    n_param = 4\n",
    "    th = np.zeros((n_param,1))\n",
    "    \n",
    "    for _ in range(num_trials):\n",
    "        delta = np.random.normal(0.0, exp_noise, (n_param, n_delta))\n",
    "        returns_p = func(th + delta)\n",
    "        returns_n = func(th - delta)\n",
    "                \n",
    "        #print(returns.std())\n",
    "        th = th + np.array(step_size/(n_delta)*np.sum((returns_p-returns_n)*delta,1)).reshape(n_param,-1)\n",
    "        \n",
    "    return th\n",
    "\n",
    "\n",
    "\n",
    "#Augmented Random Search V1 (divide update step by std of rewards)\n",
    "def ars(func, step_size = 1, n_delta = 10, exp_noise = .03,num_trials = 1000):\n",
    "    n_param = 4\n",
    "    th = np.zeros((n_param,1))\n",
    "    \n",
    "    for _ in range(num_trials):\n",
    "        delta = np.random.normal(0.0, exp_noise, (n_param, n_delta))\n",
    "        _,_,returns_p = func(th + delta)\n",
    "        _,_,returns_n = func(th - delta)\n",
    "        returns = np.concatenate((returns_p, returns_n))\n",
    "        \n",
    "        \n",
    "        #print(returns.std())\n",
    "        th = th + np.array(step_size/(n_delta*returns.std()+1e-6)*np.sum((returns_p-returns_n)*delta,1)).reshape(n_param,-1)\n",
    "        \n",
    "    return th\n",
    "        \n",
    "    \n",
    "#Augmented Random Search V2 (divide by std of rewards std of rewards, normalize states)\n",
    "def ars_v2(func, step_size = 1, n_delta = 10, exp_noise = .03, num_trials = 1000):\n",
    "    n_param = 4\n",
    "    th = torch.zeros((n_param,1))\n",
    "    s_mean = torch.zeros((n_param,1))\n",
    "    s_stdv  = torch.ones((n_param,1))\n",
    "    policy = LinearNet(n_param,1) \n",
    "    total_steps = 0 \n",
    "    \n",
    "    exp_dist = torch.distributions.Normal(torch.zeros(n_param),torch.ones(n_param)*exp_noise)\n",
    "    \n",
    "    for _ in range(num_trials):\n",
    "        delta = exp_dist.sample().reshape(n_param,1)\n",
    "        \n",
    "        policy.layer.weight[0,:] = (th + delta).reshape(-1); \n",
    "        states_p,_,returns_p = func(policy)\n",
    "        \n",
    "        policy.layer.weight[0,:] = (th + delta).reshape(-1); \n",
    "        states_n,_,returns_n = func(policy)\n",
    "        \n",
    "        returns = torch.cat((returns_p, returns_n))\n",
    "        states = torch.cat((states_p, states_n))\n",
    "        \n",
    "        ep_steps = states.shape[0]\n",
    "        s_mean = (states.mean(0)*ep_steps + s_mean*total_steps)/(total_steps + ep_steps)\n",
    "        s_stdv = (states.std(0)*ep_steps + s_stdv*total_steps)/(total_steps + ep_steps)\n",
    "        total_steps += ep_steps\n",
    "        \n",
    "        policy.state_means = s_mean\n",
    "        policy.state_var = s_stdv\n",
    "        \n",
    "        #print(returns.std())\n",
    "        th = th + np.array(step_size/(n_delta*returns.std()+1e-6)*np.sum((returns_p-returns_n)*delta,1)).reshape(n_param,-1)\n",
    "        \n",
    "    return th\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (100) must match the size of tensor b (4) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-130-34f09175dca8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvec_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpend_rollout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpolicy\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mars_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpend_rollout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpend_rollout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-129-96809cb5e95f>\u001b[0m in \u001b[0;36mars_v2\u001b[0;34m(func, step_size, n_delta, exp_noise, num_trials)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m#print(returns.std())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_delta\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturns_p\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mreturns_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_param\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (100) must match the size of tensor b (4) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "vec_env = lambda vec: np.array([pend_rollout(x) for x in vec])\n",
    "policy  = ars_v2(pend_rollout)\n",
    "print(policy)\n",
    "print(pend_rollout(policy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1275,  0.3000, -0.0990, -0.4775], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = LinearNet(4,1)\n",
    "policy.layer.weight[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda3",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
