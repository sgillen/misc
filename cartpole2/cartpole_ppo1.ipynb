{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This uses the open AI gym baseline with some slight modifications. Mostly copied code from here\n",
    "https://github.com/openai/baselines/tree/master/baselines/ppo1. Looks like the version I got from pip and the version currently on master don't quite sync up. (For example there is no tf_util.save_state fcn so we save manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to /var/folders/qq/gpxz4l6s1tndfdhysbz8bdym0000gn/T/openai-2018-12-06-18-02-10-667489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sgillen/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from baselines.common.cmd_util import make_mujoco_env, mujoco_arg_parser\n",
    "from baselines.common import tf_util as U\n",
    "import tensorflow as tf\n",
    "from baselines import logger\n",
    "import os\n",
    "import sys\n",
    "from baselines.ppo1 import mlp_policy, pposgd_simple\n",
    "\n",
    "import gym\n",
    "import seagul.envs\n",
    "import policies.mlp_relu_policy as mlp_relu_policy\n",
    "\n",
    "import numpy as np\n",
    "from mpl_toolkits import mplot3d\n",
    "%matplotlib ipympl\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "#Needed for saving \n",
    "import errno, datetime, time, inspect\n",
    "\n",
    "def train(env_id, num_timesteps, seed=0):\n",
    "\n",
    "    U.make_session(num_cpu=16).__enter__()\n",
    "    \n",
    "    def policy_fn(name, ob_space, ac_space):\n",
    "        #return mlp_policy.MlpPolicy(name=name, ob_space=ob_space, ac_space=ac_space, hid_size=64, num_hid_layers=64)\n",
    "        return mlp_relu_policy.ReluMlpPolicy(name=name, ob_space=ob_space, ac_space=ac_space, hid_size=64, num_hid_layers=4)\n",
    "\n",
    "    env = gym.make(env_id)\n",
    "    pi = pposgd_simple.learn(env, policy_fn,\n",
    "            max_timesteps=num_timesteps,\n",
    "            timesteps_per_actorbatch=2048,\n",
    "            clip_param=0.2, entcoeff=0.0,\n",
    "            optim_epochs=10, optim_stepsize=3e-4, optim_batchsize=64,\n",
    "            gamma=0.99, lam=0.95, schedule='linear',\n",
    "        )\n",
    "    env.close()\n",
    "   \n",
    "    return pi\n",
    "\n",
    "\n",
    "\n",
    "def save_results(filename, description = None):\n",
    "    \"\"\" \n",
    "    description: saves the results of a run of the second cell (the one that calls train) in this notebook\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    save_dir = \"data/\" + filename + \"/\"\n",
    "    os.makedirs(save_dir)\n",
    "    \n",
    "    if description is None:\n",
    "        description  = input(\"please enter a description of the run\")\n",
    "        \n",
    "    datetime_str = str(datetime.datetime.today())\n",
    "    datetime_str = datetime_str.replace(\" \", \"_\")\n",
    "    \n",
    "    runtime_str = str(datetime.timedelta(seconds = runtime))\n",
    "    \n",
    "    readme = open(save_dir + \"README.txt\", \"w+\")\n",
    "    readme.write(\"datetime: \" + datetime_str + \"\\n\\n\")\n",
    "    readme.write(\"enviroment: \" + env_name + \"\\n\\n\")\n",
    "    readme.write(\"description: \" + description + \"\\n\\n\")\n",
    "    readme.write(\"time_elapsed: \" + runtime_str + \"\\n\\n\")\n",
    "    readme.write(\"num_timesteps: \" + str(num_timesteps) + \"\\n\\n\")\n",
    "    readme.write(\"seed: \" + str(seed) + \"\\n\\n\")\n",
    "    readme.close()\n",
    "\n",
    "    # TODO add code snippets that correspond to the run\n",
    "    # TODO somehow store the tensorboard logs here after the fact\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(tf.get_default_session(), save_dir + filename)\n",
    "    \n",
    "    os.rename(\"./tmp_logs/\", save_dir + \"tensorboard\")\n",
    "   \n",
    "   \n",
    "#env_name = \"Acrobot-v1\"\n",
    "env_name = \"InvertedPendulum-v2\"\n",
    "#env_name = 'InvertedPendulumPyBulletEnv-v0'\n",
    "#env_name = \"su_cartpole_et-v0\"\n",
    "#env_name = \"InvertedDoublePendulum-v2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Iteration 0 ************\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "     -0.00218 |       0.00000 |      24.90593 |       0.00011 |       1.41553\n",
      "     -0.01169 |       0.00000 |      21.33840 |       0.00210 |       1.40883\n",
      "     -0.01960 |       0.00000 |      13.73937 |       0.01204 |       1.40406\n",
      "     -0.02225 |       0.00000 |       6.67395 |       0.01329 |       1.40038\n",
      "     -0.02368 |       0.00000 |       4.95351 |       0.01354 |       1.39781\n",
      "     -0.02464 |       0.00000 |       4.55235 |       0.01399 |       1.39412\n",
      "     -0.02576 |       0.00000 |       4.32681 |       0.01549 |       1.39097\n",
      "     -0.02665 |       0.00000 |       4.23610 |       0.01673 |       1.38777\n",
      "     -0.02737 |       0.00000 |       4.19393 |       0.01652 |       1.38482\n",
      "     -0.02766 |       0.00000 |       4.23136 |       0.01757 |       1.38171\n",
      "Evaluating losses...\n",
      "     -0.02956 |       0.00000 |       4.17589 |       0.01711 |       1.38006\n",
      "----------------------------------\n",
      "| EpisodesSoFar   | 267          |\n",
      "| EpLenMean       | 7.47         |\n",
      "| EpRewMean       | 7.47         |\n",
      "| EpThisIter      | 267          |\n",
      "| ev_tdlam_before | 0.000689     |\n",
      "| loss_ent        | 1.3800646    |\n",
      "| loss_kl         | 0.017106893  |\n",
      "| loss_pol_entpen | 0.0          |\n",
      "| loss_pol_surr   | -0.029564125 |\n",
      "| loss_vf_loss    | 4.175888     |\n",
      "| TimeElapsed     | 3.53         |\n",
      "| TimestepsSoFar  | 2047         |\n",
      "----------------------------------\n",
      "load_state method is deprecated, please use load_variables instead\n",
      "INFO:tensorflow:Restoring parameters from /Users/sgillen/work_dir/ucsb/sgillen_research/cartpole/data/invertedpendulum_3layer/invertedpendulum_3layer\n"
     ]
    }
   ],
   "source": [
    "# comment one of these lines to switch between loading weights or training them from scratch\n",
    "load_pretrained_network = True\n",
    "#load_pretrained_network = False\n",
    "\n",
    "\n",
    "if load_pretrained_network: #load the weights\n",
    "    save_name = 'invertedpendulum_3layer'\n",
    "    \n",
    "    pi = train(env_name, num_timesteps=1, seed=0)\n",
    "    # TODO eventually need to switch to .load_variables() instead of U.load_state() but this didn't work by default for me\n",
    "    U.load_state(os.getcwd() + '/data/'+ save_name + '/' + save_name)\n",
    "    \n",
    "else: #run the RL algorithm\n",
    "    num_timesteps = 2e6\n",
    "    seed = 0\n",
    "    \n",
    "    print(\"training\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    logger.configure(dir = \"./tmp_logs\", format_strs=[\"tensorboard\"] )\n",
    "    with tf.device(\"/cpu:0\"):    \n",
    "        pi= train(env_name, num_timesteps=num_timesteps, seed=seed)\n",
    "\n",
    "    runtime = time.time() - start_time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plays out a trained policy\n",
    "\n",
    "#env = make_mujoco_env(env_name,seed=0)\n",
    "env = gym.make(env_name)\n",
    "ob = env.reset()     \n",
    "\n",
    "while True:\n",
    "    action = pi.act(stochastic=False, ob=ob)[0]\n",
    "    ob, _, done, _ =  env.step(action)\n",
    "    #if reward == 1:\n",
    "    #    print(\"balanced\")\n",
    "    env.render()\n",
    "    if done:\n",
    "        ob = env.reset()\n",
    "        \n",
    "#U.save_state(\"./saved/5mil_flat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.24696875, -0.23682539, -0.16115585, -0.2555738 , -0.21993473,\n",
       "       -0.21259777, -0.19329132, -0.2441551 , -0.19577181,  0.13270849,\n",
       "        0.32211903, -0.33642697,  0.19466048,  0.16979927,  0.28151765,\n",
       "       -0.19948047,  0.18644999,  0.22629759,  0.24678789, -0.17854922,\n",
       "        0.1880423 ,  0.21452071, -0.0797731 , -0.26142293,  0.25687432,\n",
       "       -0.22584982, -0.10202789, -0.19495583, -0.18868645,  0.22214413,\n",
       "       -0.26131016, -0.28009197,  0.2441879 , -0.11879358,  0.20997407,\n",
       "       -0.30982113,  0.3346755 , -0.27933925,  0.30527967,  0.16208059,\n",
       "       -0.14038529,  0.32242414,  0.22511746,  0.30295438,  0.24446884,\n",
       "       -0.28062847,  0.248032  , -0.2782329 , -0.1831958 ,  0.21735889,\n",
       "        0.32385787, -0.23780961, -0.22269765, -0.22899884, -0.17545885,\n",
       "       -0.29416275,  0.27586707, -0.3017498 ,  0.27145833,  0.24073283,\n",
       "        0.20933826,  0.28276113,  0.33492553,  0.23656006], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_weights = pi.get_variables()\n",
    "fc1 = all_weights[4]\n",
    "fc1_weights = fc1.value()\n",
    "fc1_weights.eval() # only positive weights contribute anything\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#input_iter = itertools.combinations_with_replacement(range(-10,11),4)\n",
    "#input_data = np.array([np.array(x) for x in input_iter],dtype='float32')\n",
    "#output_data = np.array([pi.act(0, x)[0] for x in input_data],dtype='float32')\n",
    "\n",
    "input_iter = itertools.combinations_with_replacement(range(-10,11),2)\n",
    "input_data = np.array([np.concatenate((np.zeros(2), np.array(x))) for x in input_iter],dtype='float32')\n",
    "output_data = np.array([pi.act(0, x)[0] for x in input_data],dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "regr.fit(input_data,output_data.T.flatten())\n",
    "#regr.fit(input_data,output_data)\n",
    "#regr.fit(index, output_data.T.flatten())\n",
    "\n",
    "lin_predict = regr.predict(input_data)\n",
    "#lin_predict = regr.predict(index)\n",
    "\n",
    "print(\"coefs are\", regr.coef_)\n",
    "print(\"mean sqared error:\", mean_squared_error(lin_predict, output_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(output_data)\n",
    "plt.figure()\n",
    "plt.plot(lin_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_data = np.array([[x, 0, 0, 0] for x in range(-10,11)])\n",
    "output_data = np.array([pi.act(0, x)[0] for x in input_data])\n",
    "plt.plot(input_data[:,0], output_data)\n",
    "plt.figure()\n",
    "\n",
    "input_data = np.array([[0, x, 0, 0] for x in range(-10,11)])\n",
    "output_data = np.array([pi.act(0, x)[0] for x in input_data])\n",
    "plt.plot(input_data[:,1], output_data)\n",
    "plt.figure()\n",
    "\n",
    "input_data = np.array([[0, 0, x, 0] for x in range(-10,11)])\n",
    "output_data = np.array([pi.act(0, x)[0] for x in input_data])\n",
    "plt.plot(input_data[:,2], output_data)\n",
    "plt.figure()\n",
    "\n",
    "input_data = np.array([[0, 0, 0, x] for x in range(-10,11)])\n",
    "output_data = np.array([pi.act(0, x)[0] for x in input_data])\n",
    "plt.plot(input_data[:,3], output_data)\n",
    "plt.figure()\n",
    "\n",
    "input_data = np.array([[x, x, x, x] for x in range(-10,11)])\n",
    "output_data = np.array([pi.act(0, x)[0] for x in input_data])\n",
    "plt.plot(input_data[:,0], output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = input_data[:,2]\n",
    "y = input_data[:,3]\n",
    "z= output_data.flatten()\n",
    "z2 = lin_predict.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_trisurf(x, y, z, cmap='viridis', edgecolor='none');\n",
    "\n",
    "ax2 = plt.axes(projection='3d')\n",
    "ax2.plot_trisurf(x, y, z2, cmap='viridis', edgecolor='none');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "all_weights = pi.get_variables()\n",
    "\n",
    "# I'll fix this later..\n",
    "kernel0 = all_weights[13].value().eval()\n",
    "bias0   = all_weights[14].value().eval()\n",
    "\n",
    "kernel1 = all_weights[15].value().eval()\n",
    "bias1   = all_weights[16].value().eval()\n",
    "\n",
    "kernel2 = all_weights[17].value().eval()\n",
    "bias2   = all_weights[18].value().eval()\n",
    "\n",
    "name_dict = {\"kernel0\": kernel0, \"kernel1\":kernel1, \"kernel2\":kernel2, \"bias0\":bias0, \"bias1\":bias1, \"bias2\":bias2}\n",
    "scipy.io.savemat(\"savemat_test\", name_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
