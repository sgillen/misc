{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from numpy import cos, sin, pi\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.integrate as integrate\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "from seagul.sims.cartpole import Cartpole \n",
    "from seagul.nn import make_histories, fit_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define some constants\n",
    "\n",
    "# time vector, if you use the default solver: doesn't actually affect the integration, only what times it records our state variable at\n",
    "dt = 0.1\n",
    "tmax = 8.0\n",
    "t_eval = np.arange(0.0, tmax, dt)\n",
    "\n",
    "# Cartpole is a class we defined that takes care of the simulation/animation of the cartpole\n",
    "bot = Cartpole()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run a bunch of trials using the energy shaping controller\n",
    "num_trials = 5 # This is the number of intital conditions to try, note the total number of trials is num_trials*num_trials\n",
    "\n",
    "min_theta = 0\n",
    "max_theta = 0\n",
    "\n",
    "min_thdot = -1\n",
    "max_thdot = 1\n",
    "\n",
    "# we'll iterate through these two\n",
    "theta_vals = np.linspace(min_theta, max_theta, num_trials)\n",
    "thdot_vals = np.linspace(min_thdot, max_thdot, num_trials)\n",
    "\n",
    "# and keep these two constant\n",
    "x = 0\n",
    "xdot = 0\n",
    "\n",
    "states = np.zeros((len(t_eval), num_trials, num_trials, 4))\n",
    "actions = np.zeros((len(t_eval), num_trials, num_trials, 1))\n",
    "\n",
    "\n",
    "for i, theta in enumerate(theta_vals):\n",
    "    for j, thdot in enumerate(thdot_vals):\n",
    "\n",
    "        # initial state\n",
    "        init_state = np.array([theta, x, thdot, xdot])\n",
    "        \n",
    "        # integrate the ODE (by default this is equivalent to ode45)\n",
    "        sol = integrate.solve_ivp(bot.derivs, (0,tmax), init_state, t_eval = t_eval, max_step = .1)\n",
    "        if not sol.success:\n",
    "            print(\"warning: solver failed with intial conditions: \", init_state )\n",
    "        \n",
    "        # TODO think about doing this without a dimension per changing parameter..\n",
    "        states[:,i,j,:] = sol.y.T\n",
    "        \n",
    "        #TODO, really don't like this\n",
    "        for t in range(len(t_eval)):\n",
    "            actions[t,i,j] = bot.control(0, states[t,i,j,:]) \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Animate the cart (optional) \n",
    "ani = bot.animate_cart(t_eval, states[:,0,0,:])\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and train the feedforward network\n",
    "\n",
    "ff_model = nn.Sequential(\n",
    "    nn.Linear(4,12),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(12,12),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(12,2),\n",
    "    nn.Softmax(dim=-1)\n",
    ")\n",
    "\n",
    "def select_action(policy, state):\n",
    "    m = Categorical(policy(torch.Tensor(state)))\n",
    "    controller = m.sample()\n",
    "    \n",
    "    if controller == torch.Tensor(0):\n",
    "        action = bot.swingup_control(0,state[0:1])\n",
    "    else:\n",
    "        action = bot.balance_control(0,state[0:1])\n",
    "    \n",
    "    logprob = m.log_prob(action)\n",
    "    return action.detach().numpy(), logprob\n",
    "\n",
    "\n",
    "def make_sw_controller(model):\n",
    "    def nn_controller(t, q):\n",
    "        if model(q):\n",
    "            return model(torch.tensor(q, dtype=torch.float32))\n",
    "        else:\n",
    "            # balancing\n",
    "            # LQR: K values from MATLAB\n",
    "            k1 = 140.560\n",
    "            k2 = -3.162\n",
    "            k3 = 41.772\n",
    "            k4 = -8.314\n",
    "            u = -(k1 * (q[0] - pi) + k2 * q[1] + k3 * q[2] + k4 * q[3])\n",
    "            return u\n",
    "        \n",
    "    return nn_controller\n",
    "\n",
    "\n",
    "class SwitchCartpole(Cartpole): \n",
    "    \n",
    "    def swingup_control(self,t,q):\n",
    "            # energy error: Ee\n",
    "            Ee = 0.5 * self.mp * self.L * self.L * q[2] ** 2 - self.mp * self.g * self.L * (1 + cos(q[0]))\n",
    "            # energy control gain:\n",
    "            k = 0.23\n",
    "            # input acceleration: A (of cart)\n",
    "            A = k * Ee * cos(q[0]) * q[2]\n",
    "            # convert A to u (using EOM)\n",
    "            delta = self.mp * sin(q[0]) ** 2 + self.mc\n",
    "            u = A * delta - self.mp * self.L * (q[2] ** 2) * sin(q[0]) - self.mp * self.g * sin(q[2]) * cos(q[2])\n",
    "            \n",
    "    def balance_control(self, t,q):\n",
    "            k1 = 140.560\n",
    "            k2 = -3.162\n",
    "            k3 = 41.772\n",
    "            k4 = -8.314\n",
    "            u = -(k1 * (q[0] - pi) + k2 * q[1] + k3 * q[2] + k4 * q[3])\n",
    "\n",
    "\n",
    "            \n",
    "swing_bot = SwitchCartpole()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and train the lookback network\n",
    "\n",
    "look_back = 3\n",
    "\n",
    "lb_model = nn.Sequential(\n",
    "    nn.Linear(4 * look_back, 12*look_back),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(12 * look_back, 12*look_back),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(12 * look_back, 1)\n",
    ")\n",
    "\n",
    "state_lb = make_histories(states.reshape(-1,4), look_back)\n",
    "\n",
    "state_train = state_lb.reshape(-1,look_back*4)\n",
    "action_train = actions.reshape(-1,1)\n",
    "\n",
    "loss_hist = fit_model(lb_model, state_train, action_train, num_epochs=200, learning_rate=1e-2)\n",
    "\n",
    "plt.plot(loss_hist)\n",
    "plt.title('simple model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.figure()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a closure that returns our NN controller\n",
    "# Might make sense to just make a subclass here rather than this closure thing.. not sure yet\n",
    "\n",
    "def make_ff_controller(model):\n",
    "    def nn_controller(t, q):\n",
    "        if (q[0] < (140 * (pi/180)) ) or (q[0] > (220 * (pi/180)) ):\n",
    "            return model(torch.tensor(q, dtype=torch.float32))\n",
    "        else:\n",
    "            # balancing\n",
    "            # LQR: K values from MATLAB\n",
    "            k1 = 140.560\n",
    "            k2 = -3.162\n",
    "            k3 = 41.772\n",
    "            k4 = -8.314\n",
    "            u = -(k1 * (q[0] - pi) + k2 * q[1] + k3 * q[2] + k4 * q[3])\n",
    "            return u\n",
    "        \n",
    "    return nn_controller\n",
    "\n",
    "\n",
    "def make_lb_controller(model):\n",
    "    def nn_controller(q):\n",
    "        if (q[0,look_back-1] < (140 * (pi/180)) ) or (q[0,look_back-1] > (220 * (pi/180)) ):\n",
    "            u = model(torch.tensor(q.reshape(1,-1), dtype=torch.float32))\n",
    "            return u[0][0]\n",
    "        else:\n",
    "            # balancing\n",
    "            # lqr: k values from matlab\n",
    "            k1 = 140.560\n",
    "            k2 = -3.162\n",
    "            k3 = 41.772\n",
    "            k4 = -8.314\n",
    "            u = -(k1 * (q[0,look_back-1] - pi) + k2 * q[1,look_back-1] + k3 * q[2,look_back-1] + k4 * q[3,look_back-1])\n",
    "            return u\n",
    "        \n",
    "    return nn_controller\n",
    "\n",
    "\n",
    "ff_control = make_ff_controller(ff_model)\n",
    "lb_control = make_lb_controller(lb_model)\n",
    "\n",
    "ff_bot = Cartpole()\n",
    "lb_bot = Cartpole(dt, Ts=1, n=3)\n",
    "\n",
    "ff_bot.control = ff_control\n",
    "lb_bot.control = lb_control\n",
    "\n",
    "# initial conditions\n",
    "theta = .4\n",
    "x = 1\n",
    "th_dot = .1 # an initial velocity, triggers the swing up control\n",
    "xdot = 0.1\n",
    "time = np.arange(0.0, 20, dt)\n",
    "\n",
    "# initial state\n",
    "init_state = np.array([theta, x, th_dot, xdot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol = integrate.solve_ivp(ff_bot.derivs, (0,tmax), init_state, t_eval = t_eval)\n",
    "y_ff = sol.y.T\n",
    "\n",
    "u_ff = np.zeros(len(t_eval))\n",
    "for t in range(len(t_eval)):\n",
    "        u_ff[t] = bot.control(t, y_ff[t]) \n",
    "\n",
    "plt.figure()\n",
    "plt.plot(y_ff[:,2])\n",
    "\n",
    "ani = bot.animate_cart(t_eval, y_ff)\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the simulation for the Feedforward look back network\n",
    "\n",
    "# integrate the ODE using scipy.integrate.\n",
    "#y_lb = integrate.odeint(lb_bot.derivs_dig_lb, init_state, time)\n",
    "\n",
    "sol = integrate.solve_ivp(lb_bot.derivs_dig_lb, (0, tmax), init_state, t_eval = t_eval)\n",
    "y_lb = sol.y.T\n",
    "\n",
    "u_lb = np.zeros(len(t_eval))\n",
    "for t in range(len(t_eval)):\n",
    "        u_lb[t] = bot.control(t, y_lb[t]) \n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(y_lb[:,2])\n",
    "\n",
    "ani = lb_bot.animate_cart(time, y_lb)\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO should add in normalization eventually\n",
    "\n",
    "y_train_mean = [y_train[:,i].mean() for i in range(y_train[0,:])]\n",
    "u_train_mean = [u_train[:,i].mean() for i in range(u_train[0,:])]\n",
    "\n",
    "y_train_std = [y_train[:,i].std() for i in range(y_train[0,:])]\n",
    "u_train_std = [u_train[:,i].std() for i in range(u_train[0,:])]\n",
    "\n",
    "\n",
    "for i in range(len(y_train[0,:])):\n",
    "    y_train[:,i] = (y_train[:,i] - y_train[:,i].mean())/y_train[:,i].std()\n",
    "\n",
    "for i in range(len(u_train[0,:])):\n",
    "    u_train[:,i] = (u_train[:,i] - u_train[:,i].mean())/u_train[:,i].std()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda3",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
